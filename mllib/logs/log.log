2018-04-24 16:53:56.0240 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-04-24 16:53:56.0804 INFO main org.spark_project.jetty.util.log - Logging initialized @1600ms
2018-04-24 16:53:56.0851 INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-04-24 16:53:56.0863 INFO main org.spark_project.jetty.server.Server - Started @1660ms
2018-04-24 16:53:56.0877 INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@569bf9eb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-24 16:53:56.0898 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@625e134e{/jobs,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0899 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@611df6e3{/jobs/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0900 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f2f577{/jobs/job,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0904 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53e211ee{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0905 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41a90fa8{/stages,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0906 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d8bbcdc{/stages/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0909 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52500920{/stages/stage,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0912 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@78aea4b9{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0913 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a65bb85{/stages/pool,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0913 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b85880b{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0914 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f936da8{/storage,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0915 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4215838f{/storage/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0916 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@452ba1db{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0916 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2289aca5{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0917 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76a36b71{/environment,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0918 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@184497d1{/environment/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0919 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9d87b{/executors,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0920 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffab045{/executors/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0920 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26fb628{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0921 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e2943ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0927 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70dd7e15{/static,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0928 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fd46303{/,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0929 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60d8c0dc{/api,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0930 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60fa3495{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-24 16:53:56.0930 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e2822{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-24 16:53:57.0190 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18ca3c62{/metrics/json,null,AVAILABLE,@Spark}
2018-04-24 16:53:57.0257 INFO main MXNetJVM - Try loading mxnet-scala from native path.
2018-04-24 16:53:57.0257 INFO main MXNetJVM - Try loading mxnet-scala-linux-x86_64-gpu from native path.
2018-04-24 16:53:57.0257 INFO main MXNetJVM - Try loading mxnet-scala-linux-x86_64-cpu from native path.
2018-04-24 16:53:57.0257 WARN main MXNetJVM - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].
2018-04-24 16:53:57.0260 INFO main ml.dmlc.mxnet.util.NativeLibraryLoader - Loading libmxnet-scala.so from /lib/native/ copying to mxnet-scala
2018-04-24 16:53:58.0023 WARN Finalizer ml.dmlc.mxnet.WarnIfNotDisposed - LEAK: [one-time warning] An instance of ml.dmlc.mxnet.Symbol was not disposed. Set property mxnet.traceLeakedObjects to true to enable tracing
2018-04-24 16:53:58.0214 INFO main org.apache.hadoop.mapred.FileInputFormat - Total input paths to process : 1
2018-04-24 16:53:58.0469 INFO main ml.dmlc.mxnet.spark.MXNet - repartitioning training set to 1 partitions
2018-04-24 16:53:58.0492 INFO Thread-17 ml.dmlc.mxnet.spark.MXNet - Starting scheduler on 192.168.10.28:33319
2018-04-24 16:53:58.0550 INFO Executor task launch worker for task 2 ml.dmlc.mxnet.spark.MXNet - Starting server ...
2018-04-24 16:53:58.0594 ERROR Executor task launch worker for task 2 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 1.0 (TID 2)
java.lang.NullPointerException
	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192)
	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192)
	at scala.collection.SeqLike$class.size(SeqLike.scala:106)
	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186)
	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69)
	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22)
	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at ml.dmlc.mxnet.spark.MXNetParams.runtimeClasspath(MXNetParams.scala:64)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$ml$dmlc$mxnet$spark$MXNet$$startPSServersInner$1$1.apply(MXNet.scala:127)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$ml$dmlc$mxnet$spark$MXNet$$startPSServersInner$1$1.apply(MXNet.scala:125)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-04-24 16:53:58.0638 WARN task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 1.0 (TID 2, localhost, executor driver): java.lang.NullPointerException
	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192)
	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192)
	at scala.collection.SeqLike$class.size(SeqLike.scala:106)
	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186)
	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69)
	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22)
	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at ml.dmlc.mxnet.spark.MXNetParams.runtimeClasspath(MXNetParams.scala:64)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$ml$dmlc$mxnet$spark$MXNet$$startPSServersInner$1$1.apply(MXNet.scala:127)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$ml$dmlc$mxnet$spark$MXNet$$startPSServersInner$1$1.apply(MXNet.scala:125)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-04-24 16:53:58.0650 ERROR task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 1.0 failed 1 times; aborting job
2018-04-24 16:53:58.0854 INFO Executor task launch worker for task 5 ml.dmlc.mxnet.spark.MXNet - Launching worker ...
2018-04-24 16:53:58.0854 INFO Executor task launch worker for task 5 ml.dmlc.mxnet.spark.MXNet - Batch 128
2018-04-24 17:12:30.0883 INFO Thread-14 ml.dmlc.mxnet.util.NativeLibraryLoader - Deleting /tmp/mxnet2152469520186656124/mxnet-scala
2018-04-24 17:12:30.0883 INFO Thread-14 ml.dmlc.mxnet.util.NativeLibraryLoader - Deleting /tmp/mxnet2152469520186656124
2018-04-24 17:12:30.0890 INFO Thread-2 org.spark_project.jetty.server.AbstractConnector - Stopped Spark@569bf9eb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-24 17:12:30.0897 ERROR main ml.dmlc.mxnet.spark.example.ClassificationExample - Job 2 cancelled because SparkContext was shut down
org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:837)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:835)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:835)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1838)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1751)
	at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1924)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1923)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:572)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1988)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:927)
	at ml.dmlc.mxnet.spark.MXNet.trainModel(MXNet.scala:237)
	at ml.dmlc.mxnet.spark.MXNet.fit(MXNet.scala:257)
	at ml.dmlc.mxnet.spark.example.ClassificationSimple$.main(ClassificationSimple.scala:58)
	at ml.dmlc.mxnet.spark.example.ClassificationSimple.main(ClassificationSimple.scala)
